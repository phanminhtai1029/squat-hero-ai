# ğŸ“‹ Káº¿ Hoáº¡ch Thá»±c Hiá»‡n MVP - Yoga Pose AI

> **Má»¥c tiÃªu**: XÃ¢y dá»±ng há»‡ thá»‘ng nháº­n diá»‡n yoga poses vá»›i rule-based approach, cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng trong 1 tuáº§n.

---

## ğŸ“Š Tá»•ng Quan

### Pipeline ÄÆ¡n Giáº£n

```
Input: Webcam/Video
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1-2-3: GIá»NG CÅ¨ (Ä‘Ã£ cÃ³ sáºµn)                                           â”‚
â”‚  Frame Capture â†’ Person Detection (YOLO) â†’ Pose Estimation (MediaPipe)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼ 13 Keypoints (x, y, z, visibility)
    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: FRAME CLASSIFICATION (Rule-based)                                   â”‚
â”‚  Input: Pose history (last 5 frames)                                         â”‚
â”‚  Output: KEY_POSE / TRANSITION                                               â”‚
â”‚  Method: Velocity threshold                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼ Chá»‰ xá»­ lÃ½ náº¿u KEY_POSE
    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: POSE MATCHING (Rule-based)                                          â”‚
â”‚  Input: Current pose angles                                                  â”‚
â”‚  Output: Pose name + Similarity %                                            â”‚
â”‚  Method: Cosine similarity vá»›i angle database                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
Output: "Warrior II - 87% match"
```

### Timeline

| Phase | Task | Thá»i gian |
|-------|------|-----------|
| Phase 1 | Setup & Refactor | 1 ngÃ y |
| Phase 2 | Frame Classifier | 1 ngÃ y |
| Phase 3 | Pose Matcher | 1-2 ngÃ y |
| Phase 4 | Pose Database | 1 ngÃ y |
| Phase 5 | Testing & Evaluation | 1-2 ngÃ y |
| **Tá»•ng** | | **5-7 ngÃ y** |

---

## ğŸ”§ Phase 1: Setup & Refactor (1 ngÃ y)

### 1.1 Má»¥c tiÃªu
- Refactor code hiá»‡n táº¡i thÃ nh 5 steps rÃµ rÃ ng
- TÃ¡ch riÃªng tá»«ng module

### 1.2 Cáº¥u trÃºc thÆ° má»¥c má»›i

```
squat-hero-ai/
â”œâ”€â”€ main.py                          # Entry point
â”œâ”€â”€ config.py                        # Configuration
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ step1_frame_capture.py       # Giá»¯ nguyÃªn
â”‚   â”œâ”€â”€ step2_person_detection.py    # Giá»¯ nguyÃªn
â”‚   â”œâ”€â”€ step3_pose_estimation.py     # Giá»¯ nguyÃªn
â”‚   â”œâ”€â”€ step4_frame_classifier.py    # Má»šI
â”‚   â””â”€â”€ step5_pose_matcher.py        # Má»šI
â”œâ”€â”€ data/
â”‚   â””â”€â”€ pose_database.yaml           # Reference poses
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ angle_calculator.py          # TÃ­nh gÃ³c
â”‚   â”œâ”€â”€ pose_normalizer.py           # Normalize pose
â”‚   â””â”€â”€ visualization.py             # Giá»¯ nguyÃªn
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ evaluate_frame_classifier.py
â”‚   â”œâ”€â”€ evaluate_pose_matcher.py
â”‚   â””â”€â”€ evaluate_pipeline.py
â””â”€â”€ tests/
    â””â”€â”€ test_data/                   # Test videos/images
```

### 1.3 Deliverables
- [ ] Refactored codebase
- [ ] Step 1-3 hoáº¡t Ä‘á»™ng nhÆ° cÅ©
- [ ] Placeholder cho Step 4-5

---

## ğŸ”§ Phase 2: Frame Classifier (1 ngÃ y)

### 2.1 Algorithm

```python
# Pseudo-code
class RuleBasedFrameClassifier:
    def __init__(self, window_size=5, velocity_threshold=0.02):
        self.window_size = window_size
        self.threshold = velocity_threshold
        self.history = []  # LÆ°u N frames gáº§n nháº¥t
    
    def classify(self, current_pose):
        self.history.append(current_pose)
        if len(self.history) > self.window_size:
            self.history.pop(0)
        
        if len(self.history) < 2:
            return "TRANSITION"
        
        # TÃ­nh velocity trung bÃ¬nh
        velocity = self.compute_average_velocity()
        
        if velocity < self.threshold:
            return "KEY_POSE"
        else:
            return "TRANSITION"
    
    def compute_average_velocity(self):
        total_velocity = 0
        for i in range(1, len(self.history)):
            prev = self.history[i-1]
            curr = self.history[i]
            diff = np.abs(curr - prev)
            total_velocity += np.mean(diff)
        return total_velocity / (len(self.history) - 1)
```

### 2.2 Parameters cáº§n tune

| Parameter | GiÃ¡ trá»‹ Ä‘á» xuáº¥t | Ã nghÄ©a |
|-----------|-----------------|---------|
| `window_size` | 5 frames | Sá»‘ frames Ä‘á»ƒ tÃ­nh velocity |
| `velocity_threshold` | 0.02 | NgÆ°á»¡ng phÃ¢n biá»‡t KEY_POSE/TRANSITION |

### 2.3 Evaluation Metrics

#### Dataset cáº§n chuáº©n bá»‹
```
test_data/frame_classification/
â”œâ”€â”€ video_001.mp4
â”œâ”€â”€ video_001_labels.json  # Ground truth: [0,0,1,1,1,0,0,0,...]
â”œâ”€â”€ video_002.mp4
â”œâ”€â”€ video_002_labels.json
â””â”€â”€ ...
```

#### Metrics

| Metric | CÃ´ng thá»©c | Má»¥c tiÃªu |
|--------|-----------|----------|
| **Accuracy** | (TP + TN) / Total | > 85% |
| **Precision (KEY_POSE)** | TP_key / (TP_key + FP_key) | > 80% |
| **Recall (KEY_POSE)** | TP_key / (TP_key + FN_key) | > 90% |
| **F1 Score** | 2 * P * R / (P + R) | > 85% |

> **LÆ°u Ã½**: Recall quan trá»ng hÆ¡n Precision! Bá» sÃ³t KEY_POSE â†’ khÃ´ng match â†’ tá»‡ hÆ¡n lÃ  match nháº§m TRANSITION.

#### Evaluation Script

```python
def evaluate_frame_classifier(classifier, test_videos):
    results = {
        'total': 0,
        'correct': 0,
        'tp_key': 0, 'fp_key': 0, 'fn_key': 0,
        'tp_trans': 0, 'fp_trans': 0, 'fn_trans': 0
    }
    
    for video, labels in test_videos:
        for frame, true_label in zip(video.frames(), labels):
            pred_label = classifier.classify(frame.pose)
            
            results['total'] += 1
            if pred_label == true_label:
                results['correct'] += 1
            
            # Update confusion matrix...
    
    accuracy = results['correct'] / results['total']
    precision_key = results['tp_key'] / (results['tp_key'] + results['fp_key'])
    recall_key = results['tp_key'] / (results['tp_key'] + results['fn_key'])
    f1_key = 2 * precision_key * recall_key / (precision_key + recall_key)
    
    return {
        'accuracy': accuracy,
        'precision_key': precision_key,
        'recall_key': recall_key,
        'f1_key': f1_key
    }
```

### 2.4 Deliverables
- [ ] `step4_frame_classifier.py` hoÃ n chá»‰nh
- [ ] Test data vá»›i ground truth labels
- [ ] Evaluation script
- [ ] BÃ¡o cÃ¡o accuracy

---

## ğŸ”§ Phase 3: Pose Matcher (1-2 ngÃ y)

### 3.1 Algorithm

```python
# Pseudo-code
class RuleBasedPoseMatcher:
    # Äá»‹nh nghÄ©a 8 gÃ³c quan trá»ng
    ANGLE_DEFINITIONS = {
        'left_elbow':    ('left_shoulder', 'left_elbow', 'left_wrist'),
        'right_elbow':   ('right_shoulder', 'right_elbow', 'right_wrist'),
        'left_knee':     ('left_hip', 'left_knee', 'left_ankle'),
        'right_knee':    ('right_hip', 'right_knee', 'right_ankle'),
        'left_hip':      ('left_shoulder', 'left_hip', 'left_knee'),
        'right_hip':     ('right_shoulder', 'right_hip', 'right_knee'),
        'left_shoulder': ('left_elbow', 'left_shoulder', 'left_hip'),
        'right_shoulder':('right_elbow', 'right_shoulder', 'right_hip'),
    }
    
    def __init__(self, database_path):
        self.database = self.load_database(database_path)
    
    def match(self, landmarks):
        # 1. TÃ­nh 8 gÃ³c
        current_angles = self.compute_angles(landmarks)
        
        # 2. Normalize angles to [0, 1]
        normalized_angles = [a / 180.0 for a in current_angles]
        
        # 3. So sÃ¡nh vá»›i database
        matches = []
        for pose_name, pose_data in self.database.items():
            ref_angles = pose_data['angles_normalized']
            similarity = self.cosine_similarity(normalized_angles, ref_angles)
            matches.append((pose_name, similarity))
        
        # 4. Sort vÃ  tráº£ vá» best match
        matches.sort(key=lambda x: -x[1])
        
        best_pose, best_similarity = matches[0]
        
        return MatchResult(
            pose_name=best_pose,
            similarity=best_similarity,
            top_3_matches=matches[:3]
        )
    
    def cosine_similarity(self, a, b):
        a = np.array(a)
        b = np.array(b)
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-6)
```

### 3.2 Angle Embedding

```
Má»—i pose Ä‘Æ°á»£c biá»ƒu diá»…n bá»Ÿi 8 gÃ³c:

Pose "Warrior II":
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  left_elbow:     175Â° (tay gáº§n tháº³ng)             â”‚
â”‚  right_elbow:    178Â° (tay gáº§n tháº³ng)             â”‚
â”‚  left_knee:      92Â°  (gáº­p 90Â°)                   â”‚
â”‚  right_knee:     168Â° (gáº§n tháº³ng)                 â”‚
â”‚  left_hip:       108Â° (nghiÃªng)                   â”‚
â”‚  right_hip:      152Â° (gáº§n tháº³ng)                 â”‚
â”‚  left_shoulder:  165Â°                             â”‚
â”‚  right_shoulder: 170Â°                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Normalized: [0.97, 0.99, 0.51, 0.93, 0.60, 0.84, 0.92, 0.94]
```

### 3.3 Similarity Threshold

| Similarity | Interpretation |
|------------|----------------|
| > 0.95 | Perfect match |
| 0.85 - 0.95 | Good match |
| 0.70 - 0.85 | Possible match, cáº§n verify |
| < 0.70 | No match / Unknown pose |

### 3.4 Evaluation Metrics

#### Dataset cáº§n chuáº©n bá»‹
```
test_data/pose_matching/
â”œâ”€â”€ warrior_i/
â”‚   â”œâ”€â”€ image_001.jpg
â”‚   â”œâ”€â”€ image_001_keypoints.json
â”‚   â”œâ”€â”€ image_002.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ warrior_ii/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ tree_pose/
â”‚   â””â”€â”€ ...
â””â”€â”€ ... (20-50 poses Ã— 10-20 images má»—i pose)
```

#### Metrics

| Metric | CÃ´ng thá»©c | Má»¥c tiÃªu |
|--------|-----------|----------|
| **Top-1 Accuracy** | ÄÃºng á»Ÿ vá»‹ trÃ­ #1 | > 80% |
| **Top-3 Accuracy** | ÄÃºng trong Top 3 | > 95% |
| **Mean Similarity (True)** | Avg similarity khi match Ä‘Ãºng | > 0.85 |
| **Mean Similarity (False)** | Avg similarity khi match sai | < 0.70 |
| **Confusion Matrix** | Pose A nháº§m thÃ nh Pose B bao nhiÃªu láº§n | Äá»ƒ debug |

#### Evaluation Script

```python
def evaluate_pose_matcher(matcher, test_data):
    results = {
        'total': 0,
        'top1_correct': 0,
        'top3_correct': 0,
        'similarities_correct': [],
        'similarities_wrong': [],
        'confusion': defaultdict(lambda: defaultdict(int))
    }
    
    for true_pose, images in test_data.items():
        for image in images:
            keypoints = extract_keypoints(image)
            match_result = matcher.match(keypoints)
            
            results['total'] += 1
            predicted_pose = match_result.pose_name
            similarity = match_result.similarity
            
            # Top-1
            if predicted_pose == true_pose:
                results['top1_correct'] += 1
                results['similarities_correct'].append(similarity)
            else:
                results['similarities_wrong'].append(similarity)
            
            # Top-3
            top3_poses = [m[0] for m in match_result.top_3_matches]
            if true_pose in top3_poses:
                results['top3_correct'] += 1
            
            # Confusion matrix
            results['confusion'][true_pose][predicted_pose] += 1
    
    return {
        'top1_accuracy': results['top1_correct'] / results['total'],
        'top3_accuracy': results['top3_correct'] / results['total'],
        'mean_sim_correct': np.mean(results['similarities_correct']),
        'mean_sim_wrong': np.mean(results['similarities_wrong']),
        'confusion_matrix': dict(results['confusion'])
    }
```

### 3.5 Deliverables
- [ ] `step5_pose_matcher.py` hoÃ n chá»‰nh
- [ ] `angle_calculator.py` utility
- [ ] Test data vá»›i ground truth labels
- [ ] Evaluation script
- [ ] Confusion matrix analysis

---

## ğŸ”§ Phase 4: Pose Database (1 ngÃ y)

### 4.1 Database Format

```yaml
# pose_database.yaml
poses:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # STANDING POSES
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  warrior_i:
    display_name: "Warrior I (Virabhadrasana I)"
    category: "standing"
    difficulty: "beginner"
    angles_degrees:
      left_elbow: 175
      right_elbow: 175
      left_knee: 95
      right_knee: 165
      left_hip: 115
      right_hip: 145
      left_shoulder: 175
      right_shoulder: 175
    angles_normalized: [0.97, 0.97, 0.53, 0.92, 0.64, 0.81, 0.97, 0.97]
    description: "Lunge vá»›i 2 tay giÆ¡ cao trÃªn Ä‘áº§u"
  
  warrior_ii:
    display_name: "Warrior II (Virabhadrasana II)"
    category: "standing"
    difficulty: "beginner"
    angles_degrees:
      left_elbow: 175
      right_elbow: 178
      left_knee: 92
      right_knee: 168
      left_hip: 108
      right_hip: 152
      left_shoulder: 165
      right_shoulder: 170
    angles_normalized: [0.97, 0.99, 0.51, 0.93, 0.60, 0.84, 0.92, 0.94]
    description: "Lunge vá»›i 2 tay dang ngang"
  
  tree_pose:
    display_name: "Tree Pose (Vrksasana)"
    category: "balancing"
    difficulty: "beginner"
    angles_degrees:
      left_elbow: 175
      right_elbow: 175
      left_knee: 170    # ChÃ¢n Ä‘á»©ng tháº³ng
      right_knee: 45    # ChÃ¢n gáº­p gÃ¡c lÃªn Ä‘Ã¹i
      left_hip: 170
      right_hip: 90
      left_shoulder: 170
      right_shoulder: 170
    angles_normalized: [0.97, 0.97, 0.94, 0.25, 0.94, 0.50, 0.94, 0.94]
    description: "Äá»©ng 1 chÃ¢n, tay cháº¯p trÆ°á»›c ngá»±c hoáº·c giÆ¡ cao"
  
  # ... thÃªm 20-50 poses khÃ¡c

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# METADATA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
metadata:
  version: "1.0"
  total_poses: 30
  last_updated: "2025-01-31"
  categories:
    - standing
    - balancing
    - seated
    - prone
    - supine
```

### 4.2 CÃ¡ch Táº¡o Database

```
BÆ°á»›c 1: Chá»n 20-50 yoga poses phá»• biáº¿n

BÆ°á»›c 2: Vá»›i má»—i pose:
    a) TÃ¬m áº£nh/video reference cá»§a pose chuáº©n
    b) Cháº¡y qua MediaPipe â†’ láº¥y keypoints
    c) TÃ­nh 8 gÃ³c
    d) Verify báº±ng máº¯t: gÃ³c cÃ³ há»£p lÃ½ khÃ´ng?
    e) ThÃªm vÃ o database

BÆ°á»›c 3: Test láº¡i vá»›i áº£nh khÃ¡c cá»§a cÃ¹ng pose
    â†’ Similarity cÃ³ > 0.85 khÃ´ng?
    â†’ Náº¿u khÃ´ng, Ä‘iá»u chá»‰nh láº¡i gÃ³c reference
```

### 4.3 Tool Há»— Trá»£ Táº¡o Database

```python
# create_database_entry.py
def create_pose_entry(image_path, pose_name):
    """Tool Ä‘á»ƒ táº¡o entry cho database."""
    
    # 1. Load image
    image = cv2.imread(image_path)
    
    # 2. Detect pose
    landmarks = mediapipe_detect(image)
    
    # 3. TÃ­nh gÃ³c
    angles = calculate_all_angles(landmarks)
    
    # 4. In ra Ä‘á»ƒ copy vÃ o database
    print(f"\n{pose_name}:")
    print(f"  angles_degrees:")
    for name, angle in angles.items():
        print(f"    {name}: {angle:.0f}")
    
    normalized = [a / 180.0 for a in angles.values()]
    print(f"  angles_normalized: {normalized}")
    
    # 5. Visualize Ä‘á»ƒ verify
    visualize_pose_with_angles(image, landmarks, angles)
    cv2.imshow("Verify", image)
    cv2.waitKey(0)

# Usage:
# python create_database_entry.py --image warrior2.jpg --name warrior_ii
```

### 4.4 Deliverables
- [ ] `pose_database.yaml` vá»›i 20-50 poses
- [ ] Tool táº¡o database entries
- [ ] Documentation cho má»—i pose

---

## ğŸ”§ Phase 5: Testing & Evaluation (1-2 ngÃ y)

### 5.1 End-to-End Pipeline Evaluation

#### Test Scenarios

| Scenario | MÃ´ táº£ | Ká»³ vá»ng |
|----------|-------|---------|
| **Happy Path** | User lÃ m pose chuáº©n, Ä‘á»©ng yÃªn | Nháº­n diá»‡n Ä‘Ãºng, similarity > 0.90 |
| **Slight Variation** | Pose hÆ¡i khÃ¡c chuáº©n (Â±10Â°) | Nháº­n diá»‡n Ä‘Ãºng, similarity 0.80-0.90 |
| **Moving** | User Ä‘ang chuyá»ƒn Ä‘á»™ng | Frame Classifier tráº£ vá» TRANSITION |
| **Unknown Pose** | Pose khÃ´ng cÃ³ trong DB | Top similarity < 0.70, cÃ³ thá»ƒ reject |
| **Bad Detection** | MediaPipe detect sai | Graceful handling, khÃ´ng crash |
| **Multiple Poses** | User lÃ m nhiá»u poses liÃªn tiáº¿p | Nháº­n diá»‡n Ä‘Ãºng tá»«ng pose |

#### Evaluation Script

```python
def evaluate_full_pipeline(pipeline, test_videos):
    """ÄÃ¡nh giÃ¡ toÃ n bá»™ pipeline end-to-end."""
    
    results = {
        'frame_classifier': {
            'total_frames': 0,
            'key_poses_detected': 0,
            'transitions_detected': 0
        },
        'pose_matcher': {
            'total_key_frames': 0,
            'correct_matches': 0,
            'top3_correct': 0,
            'avg_similarity_correct': [],
            'avg_similarity_wrong': []
        },
        'pipeline': {
            'latency_ms': [],
            'fps': []
        }
    }
    
    for video_path, ground_truth in test_videos:
        cap = cv2.VideoCapture(video_path)
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            start_time = time.time()
            
            # Run pipeline
            output = pipeline.process_frame(frame)
            
            end_time = time.time()
            latency = (end_time - start_time) * 1000
            results['pipeline']['latency_ms'].append(latency)
            
            # Evaluate frame classifier
            results['frame_classifier']['total_frames'] += 1
            if output.frame_type == 'KEY_POSE':
                results['frame_classifier']['key_poses_detected'] += 1
            else:
                results['frame_classifier']['transitions_detected'] += 1
            
            # Evaluate pose matcher (only for key frames)
            if output.frame_type == 'KEY_POSE' and output.match_result:
                results['pose_matcher']['total_key_frames'] += 1
                
                true_pose = ground_truth.get_pose_at_frame(frame_idx)
                pred_pose = output.match_result.pose_name
                similarity = output.match_result.similarity
                
                if pred_pose == true_pose:
                    results['pose_matcher']['correct_matches'] += 1
                    results['pose_matcher']['avg_similarity_correct'].append(similarity)
                else:
                    results['pose_matcher']['avg_similarity_wrong'].append(similarity)
    
    # Compute final metrics
    return {
        'frame_classifier': {
            'key_pose_ratio': results['frame_classifier']['key_poses_detected'] / 
                              results['frame_classifier']['total_frames']
        },
        'pose_matcher': {
            'top1_accuracy': results['pose_matcher']['correct_matches'] / 
                             results['pose_matcher']['total_key_frames'],
            'mean_similarity_correct': np.mean(results['pose_matcher']['avg_similarity_correct']),
            'mean_similarity_wrong': np.mean(results['pose_matcher']['avg_similarity_wrong'])
        },
        'pipeline': {
            'avg_latency_ms': np.mean(results['pipeline']['latency_ms']),
            'avg_fps': 1000 / np.mean(results['pipeline']['latency_ms'])
        }
    }
```

### 5.2 Expected Results

#### Frame Classifier

| Metric | Target | Acceptable |
|--------|--------|------------|
| Accuracy | > 90% | > 85% |
| Precision (KEY_POSE) | > 85% | > 80% |
| Recall (KEY_POSE) | > 95% | > 90% |

#### Pose Matcher

| Metric | Target | Acceptable |
|--------|--------|------------|
| Top-1 Accuracy | > 85% | > 75% |
| Top-3 Accuracy | > 98% | > 95% |
| Mean Similarity (Correct) | > 0.88 | > 0.82 |
| Mean Similarity (Wrong) | < 0.65 | < 0.72 |

#### Pipeline Performance

| Metric | Target | Acceptable |
|--------|--------|------------|
| Latency | < 50ms | < 80ms |
| FPS | > 20 | > 12 |

### 5.3 Deliverables
- [ ] End-to-end evaluation script
- [ ] Test video dataset vá»›i ground truth
- [ ] BÃ¡o cÃ¡o káº¿t quáº£ chi tiáº¿t
- [ ] Confusion matrix
- [ ] Error analysis

---

## ğŸ“ˆ Tá»•ng Káº¿t & Quyáº¿t Äá»‹nh

### Quyáº¿t Äá»‹nh Dá»±a TrÃªn Káº¿t Quáº£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DECISION TREE                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Sau Phase 5, Ä‘Ã¡nh giÃ¡ káº¿t quáº£:                                         â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Pose Matcher Top-1 Accuracy                                      â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  > 85%  â”€â”€â”€â”€â”€â”€â–¶  âœ… DONE! Ship MVP                              â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  75-85% â”€â”€â”€â”€â”€â”€â–¶  ğŸ”§ Tune thresholds, thÃªm features              â”‚    â”‚
â”‚  â”‚                   - ThÃªm relative positions                      â”‚    â”‚
â”‚  â”‚                   - ThÃªm symmetry features                       â”‚    â”‚
â”‚  â”‚                   - Tune velocity threshold                      â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  < 75%  â”€â”€â”€â”€â”€â”€â–¶  ğŸ§  Consider training simple encoder            â”‚    â”‚
â”‚  â”‚                   - Thu tháº­p thÃªm data                           â”‚    â”‚
â”‚  â”‚                   - Train MLP encoder                            â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Checkpoints

| Checkpoint | Criteria | Action náº¿u FAIL |
|------------|----------|-----------------|
| Phase 2 Done | Frame Classifier F1 > 85% | Tune window_size, velocity_threshold |
| Phase 3 Done | Pose Matcher Top-1 > 75% | ThÃªm features, tune database |
| Phase 5 Done | Pipeline FPS > 12 | Optimize code, reduce computations |

---

## ğŸ“ Appendix: Danh SÃ¡ch 30 Yoga Poses Äá» Xuáº¥t

### Beginner (15 poses)
1. Mountain Pose (Tadasana)
2. Tree Pose (Vrksasana)
3. Warrior I (Virabhadrasana I)
4. Warrior II (Virabhadrasana II)
5. Triangle Pose (Trikonasana)
6. Downward Dog (Adho Mukha Svanasana)
7. Child's Pose (Balasana)
8. Cat Pose (Marjaryasana)
9. Cow Pose (Bitilasana)
10. Cobra Pose (Bhujangasana)
11. Bridge Pose (Setu Bandhasana)
12. Seated Forward Bend (Paschimottanasana)
13. Corpse Pose (Savasana)
14. Chair Pose (Utkatasana)
15. Extended Side Angle (Utthita Parsvakonasana)

### Intermediate (15 poses)
16. Warrior III (Virabhadrasana III)
17. Half Moon (Ardha Chandrasana)
18. Eagle Pose (Garudasana)
19. Dancer Pose (Natarajasana)
20. Boat Pose (Navasana)
21. Crow Pose (Bakasana)
22. Side Plank (Vasisthasana)
23. Pigeon Pose (Eka Pada Rajakapotasana)
24. Camel Pose (Ustrasana)
25. Wheel Pose (Urdhva Dhanurasana)
26. Shoulder Stand (Sarvangasana)
27. Plow Pose (Halasana)
28. Fish Pose (Matsyasana)
29. Bow Pose (Dhanurasana)
30. Headstand Prep (Sirsasana Prep)

---

> **Ghi chÃº**: 
> - Káº¿ hoáº¡ch nÃ y cÃ³ thá»ƒ Ä‘iá»u chá»‰nh dá»±a trÃªn káº¿t quáº£ thá»±c táº¿
> - Æ¯u tiÃªn hoÃ n thÃ nh Phase 1-3 trÆ°á»›c, Phase 4-5 cÃ³ thá»ƒ má»Ÿ rá»™ng sau
> - Documentation vÃ  code comments lÃ  quan trá»ng Ä‘á»ƒ maintain sau nÃ y
