# üìã B√°o C√°o Ho√†n Ch·ªânh: Rule-Based Yoga Pose Recognition

**Ng√†y th·ª±c hi·ªán**: 2026-01-31  
**Repository**: https://github.com/phanminhtai1029/squat-hero-ai  
**Branch**: `feature/rule-based-mvp`

---

## 1. T·ªïng Quan D·ª± √Ån

### 1.1 M·ª•c Ti√™u
X√¢y d·ª±ng h·ªá th·ªëng nh·∫≠n di·ªán t∆∞ th·∫ø yoga s·ª≠ d·ª•ng **rule-based approach** (kh√¥ng training ML) ƒë·ªÉ ƒë√°nh gi√° kh·∫£ nƒÉng v√† gi·ªõi h·∫°n c·ªßa ph∆∞∆°ng ph√°p n√†y.

### 1.2 Pipeline 5 B∆∞·ªõc

```
Input (Webcam/Video/Image)
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Step 1: Frame Capture (OpenCV)                                   ‚îÇ
‚îÇ Step 2: Person Detection (YOLOv8 - pretrained)                   ‚îÇ
‚îÇ Step 3: Pose Estimation (MediaPipe - pretrained)                 ‚îÇ
‚îÇ Step 4: Frame Classification (Rule-based: velocity threshold)    ‚îÇ
‚îÇ Step 5: Pose Matching (Rule-based: similarity metrics)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
Output: Pose Name + Similarity Score
```

---

## 2. C√¥ng Vi·ªác ƒê√£ Th·ª±c Hi·ªán

### 2.1 Dataset
- T·∫£i v·ªÅ **Yoga_Poses-Dataset** t·ª´ GitHub (484 ·∫£nh, 8 poses)
- Poses: Downward Dog, Triangle, Warrior, Tree, Dancer, Half Moon, Goddess, Bound Angle

### 2.2 Refactor Codebase
**Tr∆∞·ªõc refactor:**
```
step1_frame_capture/
step2_person_cropping/
step3_pose_detection/
step4_pose_comparison/
venv/ (7.3GB duplicate)
```

**Sau refactor:**
```
pipeline/
‚îú‚îÄ‚îÄ step1_frame_capture.py
‚îú‚îÄ‚îÄ step2_person_detection.py
‚îú‚îÄ‚îÄ step3_pose_estimation.py
‚îú‚îÄ‚îÄ step4_frame_classifier.py
‚îî‚îÄ‚îÄ step5_pose_matcher.py
```
‚Üí Ti·∫øt ki·ªám ~7.3GB, code s·∫°ch h∆°n

### 2.3 Implement Rule-Based Pipeline

| Step | Algorithm/Model | M√¥ t·∫£ |
|------|----------------|-------|
| Step 1 | OpenCV VideoCapture | ƒê·ªçc frames t·ª´ camera/video |
| Step 2 | YOLOv8n (pretrained) | Detect person bounding box |
| Step 3 | MediaPipe Pose (pretrained) | Extract 33 body landmarks |
| Step 4 | Velocity Threshold | Classify KEY_POSE vs TRANSITION |
| Step 5 | Similarity Metrics | Match angles v·ªõi database |

### 2.4 Pose Database
T·∫°o `pose_database.yaml` v·ªõi 8 poses:
- 8 joint angles per pose
- Weights (importance) per angle
- Tolerance ranges (min-max acceptable)

---

## 3. Th·ª≠ Nghi·ªám & K·∫øt Qu·∫£

### 3.1 C√°c Ph∆∞∆°ng Ph√°p Matching ƒê√£ Test

| Method | C√¥ng th·ª©c | Top-1 Accuracy |
|--------|-----------|----------------|
| **Cosine Similarity** | `cos(A,B) = A¬∑B / (||A||√ó||B||)` | **43.2%** ‚≠ê |
| Euclidean Similarity | `exp(-||A-B|| √ó 2)` | 33.9% |
| Weighted Euclidean | `exp(-||w√ó(A-B)|| √ó 3)` | 34.7% |
| Combined | `0.4√óeuc + 0.3√óweight + 0.3√ótol` | 31.4% |

### 3.2 K·∫øt Qu·∫£ Chi Ti·∫øt Per-Pose

| Pose | Cosine | Euclidean | Weighted | Combined |
|------|--------|-----------|----------|----------|
| baddha_konasana | 100% | 100% | 100% | 100% |
| downward_dog | 93.3% | 100% | 100% | 100% |
| triangle | 93.3% | 6.7% | 6.7% | 0% |
| veerabhadrasana | 33.3% | 26.7% | 6.7% | 0% |
| utkata_konasana | 0% | 26.7% | 26.7% | 6.7% |
| ardha_chandrasana | 7.7% | 0% | 15.4% | 38.5% |
| vrukshasana | 13.3% | 6.7% | 6.7% | 6.7% |
| natarajasana | 0% | 0% | 13.3% | 0% |

### 3.3 Performance Metrics (t·ª´ evaluation tr∆∞·ªõc ƒë√≥)

| Metric | Gi√° tr·ªã |
|--------|---------|
| Detection Rate | 99.4% |
| Avg Latency | 37ms |
| FPS | 27 |

---

## 4. Ph√¢n T√≠ch Gi·ªõi H·∫°n Rule-Based

### 4.1 T·∫°i Sao Accuracy Th·∫•p?

1. **8 g√≥c kh√¥ng ƒë·ªß ph√¢n bi·ªát**: Nhi·ªÅu poses c√≥ g√≥c t∆∞∆°ng t·ª±
2. **Thi·∫øu th√¥ng tin v·ªã tr√≠**: G√≥c gi·ªëng nhau nh∆∞ng v·ªã tr√≠ kh√°c
3. **Bi·∫øn th·ªÉ trong dataset**: ·∫¢nh th·ª±c t·∫ø kh√°c "pose chu·∫©n"
4. **Mirror confusion**: Left/right kh√¥ng ƒë∆∞·ª£c x·ª≠ l√Ω

### 4.2 C√°c C·∫£i Thi·ªán ƒê√£ Th·ª≠

| Strategy | K·∫øt qu·∫£ |
|----------|---------|
| Euclidean thay Cosine | ‚ùå Gi·∫£m accuracy |
| Weighted angles | ‚ùå Kh√¥ng c·∫£i thi·ªán ƒë√°ng k·ªÉ |
| Angle tolerances | ‚ùå Kh√¥ng c·∫£i thi·ªán ƒë√°ng k·ªÉ |
| Combined method | ‚ùå Gi·∫£m accuracy |

### 4.3 C√°c C·∫£i Thi·ªán Kh√¥ng Kh·∫£ Thi

| Approach | T·∫°i sao kh√¥ng scale |
|----------|---------------------|
| Position features | Ph·∫£i tune cho t·ª´ng pose ‚Üí O(N) effort |
| Mirror handling | 2√ó t√≠nh to√°n cho m·ªçi frame |
| Category-first | Category c√≥ th·ªÉ r·∫•t l·ªõn, boundary kh√¥ng r√µ |
| Multi-reference | N poses √ó M refs = O(N√óM) complexity |

---

## 5. K·∫øt Lu·∫≠n

### 5.1 Rule-Based ƒê·∫°t Gi·ªõi H·∫°n

| Metric | Gi√° tr·ªã |
|--------|---------|
| Best accuracy | **43.2%** (Cosine) |
| Theoretical max (v·ªõi full tuning) | ~70-80% |
| Scalability | ‚ùå Kh√¥ng scale ƒë∆∞·ª£c |

### 5.2 V·∫•n ƒê·ªÅ C·ªët L√µi

> **Rule-based kh√¥ng c√≥ kh·∫£ nƒÉng "h·ªçc"** ƒë·ªÉ ph√¢n bi·ªát c√°c poses t∆∞∆°ng t·ª±. M·ªçi c·∫£i thi·ªán ƒë·ªÅu y√™u c·∫ßu manual tuning, kh√¥ng scalable v·ªõi nhi·ªÅu poses.

### 5.3 Khuy·∫øn Ngh·ªã

ƒê·ªÉ ƒë·∫°t accuracy >80% v√† scale v·ªõi h√†ng trƒÉm poses, c·∫ßn chuy·ªÉn sang **ML-based approach**:
- Learned pose embeddings
- Neural network classifier
- Metric learning

---

## 6. Files ƒê√£ T·∫°o/S·ª≠a

| File | M√¥ t·∫£ |
|------|-------|
| `pipeline/__init__.py` | Package exports |
| `pipeline/step1_frame_capture.py` | Frame capture module |
| `pipeline/step2_person_detection.py` | YOLO person detection |
| `pipeline/step3_pose_estimation.py` | MediaPipe pose estimation |
| `pipeline/step4_frame_classifier.py` | Velocity-based classifier |
| `pipeline/step5_pose_matcher.py` | Multi-method pose matcher |
| `utils/angle_calculator.py` | Joint angle computation |
| `data/pose_database.yaml` | 8 poses v·ªõi weights & tolerances |
| `evaluation/evaluate_pipeline.py` | Full evaluation script |
| `evaluation/evaluation_report.json` | K·∫øt qu·∫£ ƒë√°nh gi√° |
| `evaluation/comparison_results.json` | So s√°nh c√°c methods |
| `docs/RULE_BASED_REVIEW.md` | Review chi ti·∫øt |
| `docs/FILE_STRUCTURE.md` | C·∫•u tr√∫c project |
| `docs/EVALUATION_REPORT.md` | B√°o c√°o ƒë√°nh gi√° |
| `main.py` | Entry point (refactored) |

---

## 7. H∆∞·ªõng ƒêi Ti·∫øp Theo

Pending user direction - likely ML-based approach for improved accuracy and scalability.

---

**End of Report**
